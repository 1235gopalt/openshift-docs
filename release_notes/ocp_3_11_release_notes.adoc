[[release-notes-ocp-3-11-release-notes]]
= {product-title} 3.11 Release Notes
{product-author}
{product-version}
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:
:prewrap!:

toc::[]

== Overview

Red Hat {product-title} provides developers and IT organizations with a hybrid
cloud application platform for deploying both new and existing applications on
secure, scalable resources with minimal configuration and management overhead.
{product-title} supports a wide selection of programming languages and
frameworks, such as Java, Javascript, Python, Ruby, and PHP.

Built on Red Hat Enterprise Linux and Kubernetes, {product-title} provides a
secure and scalable multi-tenant operating system for todayâ€™s enterprise-class
applications, while providing integrated application runtimes and libraries.
{product-title} enables organizations to meet security, privacy, compliance, and
governance requirements.

[[ocp-311-about-this-release]]
== About This Release

Red Hat {product-title} version 3.11
(link:https://access.redhat.com/errata/RHBA-2018:2652[RHBA-2018:2652]) is now
available. This release is based on
link:https://github.com/openshift/origin/releases/tag/v3.11.0-alpha.0[OKD 3.11] and
it uses Kubernetes 1.11. New features, changes, bug fixes, and known issues that
pertain to {product-title} 3.11 are included in this topic.

{product-title} 3.11 is supported on RHEL 7.4 and 7.5 with the latest packages
from Extras, including Docker 1.13. It is also supported on Atomic Host 7.4.5
and newer.

For initial installations, see the
xref:../install/index.adoc#install-planning[Installing Clusters] documentation.

To upgrade to this release from a previous version, see the
xref:../upgrading/index.adoc#install-config-upgrading-index[Upgrading Clusters]
documentation.

{product-title} 3.11 is the last release in the 3.x stream. Large changes to the
underlying architecture and installation process are coming in version 4.0.
Additionally, the
xref:../upgrading/blue_green_deployments.adoc#upgrading-blue-green-deployments[blue-green
installation method] will be deprecated in {product-title} 4.0.


[[ocp-311-new-features-and-enhancements]]
== New Features and Enhancements

This release adds improvements related to the following components and concepts.

[[ocp-311-storage]]
=== Storage

[[ocp-311-container-storage-Interface]]
==== Container Storage Interface (Technology Preview)

Container Storage Interface (CSI) is currently in
xref:ocp-311-technology-preview[Technology Preview] and not for production
workloads.

CSI allows {product-title} to consume storage from storage backends that
implement the link:https://github.com/container-storage-interface/spec[CSI
interface] as
xref:../architecture/additional_concepts/storage.adoc#architecture-additional-concepts-storage[persistent
storage].

See
xref:../install_config/persistent_storage/persistent_storage_csi.adoc#install-config-persistent-storage-persistent-storage-csi[Persistent
Storage Using Container Storage Interface (CSI)] for more information.

[[ocp-311-local-ephemeral-storage]]
==== Protection of Local Ephemeral Storage (Technology Preview)

Protection of Local Ephemeral Storage is currently in
xref:ocp-311-technology-preview[Technology Preview] and not for production
workloads.

You can now control the use of the local ephemeral storage feature on your nodes
in order to prevent users from exhausting node local storage with their pods and
other pods that happen to be on the same node.

This feature is disabled by default. If enabled, the {product-title} cluster uses
ephemeral storage to store information that does not need to persist after the
cluster is destroyed.

See xref:../install_config/configuring_ephemeral.adoc#install-config-configuring-ephemeral-storage[Configuring Ephemeral Storage] for more information.

[[ocp-311-pv-provisioning-using-openstack-manilla]]
==== Persistent Volume (PV) Provisioning Using OpenStack Manila (Technology Preview)

Persistent volume (PV) provisioning using OpenStack Manila is currently in
xref:ocp-311-technology-preview[Technology Preview] and not for production
workloads.

{product-title} is capable of provisioning PVs using the
link:https://wiki.openstack.org/wiki/Manila[OpenStack Manila] shared file system
service.

See
xref:../install_config/persistent_storage/persistent_storage_manila.adoc#persistent_storage_manila[Persistent
Storage Using OpenStack Manila] for more information.

[[ocp-311-pv-resize]]
==== PV Resize (Technology Preview)

Persistent volume (PV) resize is currently in
xref:ocp-311-technology-preview[Technology Preview] and not for production
workloads.

You can expand persistent volume claims online from {product-title} for glusterFS.

. Create a storage class with `allowVolumeExpansion=true`.
. The PVC uses the storage class and submits a claim.
. The PVC specifies a new increased size.
. The underlying PV is resized.

See
xref:../dev_guide/expanding_persistent_volumes.adoc#expanding_persistent_volumes[Expanding
Persistent Volumes] for more information.

[[ocp-311-tenant-driven-storage-snapshotting]]
==== Tenant-driven Storage Snapshotting (Technology Preview)

Tenant-driven storage snapshotting is currently in
xref:ocp-311-technology-preview[Technology Preview] and not for production
workloads.

Tenants now have the ability to leverage the underlying storage technology
backing the persistent volume (PV) assigned to them to make a snapshot of their
application data. Tenants can also now restore a given snapshot from the past to
their current application.

An external provisioner is used to access the EBS, GCE pDisk, and HostPath. This
Technology Preview feature has tested EBS and HostPath. The tenant must stop the
pods and start them manually.

. The administrator runs an external provisioner for the cluster. These are images
from the Red hat Container Catalog.

. The tenant made a PVC and owns a PV from one of the supported storage
solutions.The administrator must create a new `StorageClass` in the cluster with:
+
----
kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: snapshot-promoter
provisioner: volumesnapshot.external-storage.k8s.io/snapshot-promoter
----

. The tenant can create a snapshot of a PVC named `gce-pvc` and the resulting
snapshot will be called `snapshot-demo`.
+
----
$ oc create -f snapshot.yaml

apiVersion: volumesnapshot.external-storage.k8s.io/v1
kind: VolumeSnapshot
metadata:
  name: snapshot-demo
  namespace: myns
spec:
  persistentVolumeClaimName: gce-pvc
----

. Now, they can restore their pod to that snapshot.
+
----
$ oc create -f restore.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: snapshot-pv-provisioning-demo
  annotations:
    snapshot.alpha.kubernetes.io/snapshot: snapshot-demo
spec:
  storageClassName: snapshot-promoter
----

[[ocp-311-scale]]
=== Scale

[[ocp-311-scale-cluster-limits]]
==== Cluster Limits

Updated guidance around
xref:../scaling_performance/cluster_limits.adoc#scaling-performance-cluster-limits[Cluster
Limits] for {product-title} 3.11 is now available.

[[ocp-311-metrics-and-logging]]
=== Metrics and Logging

[[ocp-311-prometheus]]
==== Prometheus Cluster Monitoring

Prometheus cluster monitoring is now fully supported in {product-title}.

You can deploy Prometheus on an {product-title} cluster, collect Kubernetes and
infrastructure metrics, and get alerts. You can see and query metrics and alerts
on the Prometheus web dashboard.

See xref:../install_config/cluster_metrics.adoc#openshift-prometheus[Prometheus
on OpenShift] for more information.

[[ocp-311-syslog-output-plugin-for-fluentd]]
==== syslog Output Plug-in for fluentd (Technology Preview)

syslog Output Plug-in for fluentd is a feature currently in
xref:ocp-311-technology-preview[Technology Preview] and not for production
workloads.

You can send system and container logs from {product-title} nodes to external
endpoints using the syslog protocol. The fluentd syslog output plug-in supports
this.

[IMPORTANT]
====
Logs sent via syslog are not encrypted and, therefore, insecure.
====

See
xref:../install_config/aggregate_logging.adoc#sending-logs-to-external-rsyslog[Sending
Logs to an External Syslog Server] for more information.

[[ocp-311-developer-experience]]
=== Developer Experience

[[ocp-311-cli-plug-ins]]
==== CLI Plug-ins (Technology Preview)

CLI plug-ins remain in xref:ocp-311-technology-preview[Technology Preview]
and are not for production workloads.

Usually called _plug-ins_ or _binary extensions_, this feature allows you to
extend the default set of `oc` commands available and, therefore, allows you to
perform new tasks.

See xref:../cli_reference/extend_cli.adoc#cli-reference-extend-cli[Extending the
CLI] for information on how to install and write extensions for the CLI.

[[ocp-311-configure-build-trigger-without-triggering-immediately]]
==== Configure a Build Trigger Behavior without Triggering a Build Immediately

You can pause an image change trigger to allow multiple changes on the referenced
image stream before a build is started. You can also set the `paused` attribute
to true when initially adding an `ImageChangeTrigger` to a `BuildConfig` to prevent
a build from being immediately triggered.

See
xref:../dev_guide/builds/triggering_builds.adoc#image-change-trigger[Triggering
Builds] for more information.

[[ocp-311-networking]]
=== Networking

[[ocp-311-kuryr]]
==== Improved {product-title} and Red Hat OpenStack Integration with Kuryr (Technology Preview)

This feature is currently in xref:ocp-311-technology-preview[Technology
Preview] and is not for production workloads.

See xref:../admin_guide/kuryr.adoc#admin-guide-kuryr[Kuryr SDN Administration]
and
xref:../install_config/configuring_kuryrsdn.adoc#install-config-configuring-kuryr-sdn[Configuring
Kuryr SDN] for best practices in {product-title} and Red Hat OpenStack
integration.

[[ocp-311-master]]
=== Master

[[ocp-311-the-descheduler]]
==== The Descheduler (Technology Preview)

The Descheduler is currently in xref:ocp-311-technology-preview[Technology
Preview] and is not for production workloads.

The descheduler moves pods from less desirable nodes to new nodes. Pods can be
moved for various reasons, such as:

* Some nodes are under- or over-utilized.
* The original scheduling decision does not hold true any more, as taints or
labels are added to or removed from nodes, pod/node affinity requirements are
not satisfied any more.
* Some nodes failed and their pods moved to other nodes.
* New nodes are added to clusters.

See
xref:../admin_guide/scheduling/descheduler.adoc#admin-guide-descheduler[Descheduling]
for more information.

[[ocp-311-podman]]
==== Podman (Technology Preview)

Podman is currently in xref:ocp-311-technology-preview[Technology Preview] and
is not for production workloads.

Podman is a daemon-less CLI/API for running, managing, and debugging OCI containers and pods. It:

* Is fast and lightweight.
* Leverages runC.
* Provides a syntax for working with containers.
* Has remote management API via Varlink.
* Provides systemd integration and advanced namespace isolation.

For more information, see link:https://blog.openshift.com/crictl-vs-podman/[Crictl Vs Podman].

[[ocp-311-node-problem-detector]]
==== Node Problem Detector (Technology Preview)

The Node Problem Detector is currently in xref:ocp-311-technology-preview[Technology
Preview] and is not for production workloads.

The Node Problem Detector monitors the health of your nodes by finding certain
problems and reporting these problems to the API server, where external
controllers could take action. The Node Problem Detector is a daemon that runs
on each node as a daemonSet.  The daemon tries to make the cluster aware of node
level faults that should make the node not schedulable. When you start the Node
Problem Detector, you tell it a port over which it should broadcast the issues
it finds. The detector allows you to load sub-daemons to do the data collection.
There are three as of today.  Issues found by the problem daemon can be
classified as `NodeCondition`.

Problem daemons:

* Kernel Monitor: Monitors kernel log via journald and reports problems according
to regex patterns.
* AbrtAdaptor: Monitors the node for kernel problems and application crashes from
journald.
* CustomerPluginMonitor: Allows you to test for any condition and exit on a `0` or
`1` should your condition not be met.

See
xref:../admin_guide/node_problem_detector.adoc#admin-guide-node-problem-detector[Node
Problem Detector] for more information.

[[ocp-311-cluster-autoscaling]]
==== Cluster Autoscaling (AWS Only)

You can configure an auto-scaler on your {product-title} cluster in
Amazon Web Services (AWS) to provide elasticity for yor application
workload. The auto-scaler ensures that enough nodes are active to run
your pods and that the number of active nodes is proportional to
current demand.

See [Configuring the cluster auto-scaler in AWS] for more information.

[[ocp-311-web-console]]
=== Web console

[[ocp-311-cluster-admin-console]]
==== Cluster Administrator Console

{product-title} 3.11 introduces a cluster administrator console tailored toward
application development and cluster administrator personas.

See
xref:../install/configuring_inventory_file.adoc#install-config-configuring-inventory-file[Configuring
Your Inventory File] for details on configuring the cluster console.

[[ocp-311-security]]
=== Security

[[ocp-311-control-sharing-pid-namespace-between-containers]]
==== Control Sharing the PID Namespace Between Containers (Technology Preview)

Control Sharing the PID Namespace Between Containers is currently in
xref:ocp-311-technology-preview[Technology Preview] and not for production
workloads.

Use this feature to configure cooperating containers in a pod, such as a log
handler sidecar container, or to troubleshoot container images that do not
include debugging utilities like a shell.

* The feature gate `PodShareProcessNamespace` is set to `false` by default.
* Set `feature-gates=PodShareProcessNamespace=true` in  the API server,
controllers, and kubelet.
* Restart the API server, controller, and node service.
* Create a pod with the specification of `shareProcessNamespace: true`.
* Run `oc create -f <pod spec file>`.

*Caveats*

When the PID namespace is shared between containers:

* Sidecar containers are not isolated.
* Environment variables are now visible to all other processes.
* Any *kill all* semantics used within the process are now broken.
* Any `exec` processes from other containers will now show up.

See
xref:../dev_guide/expanding_persistent_volumes.adoc#expanding_persistent_volumes[Expanding
Persistent Volumes] for more information.

[[ocp-311-github-enterprise-added-as-auth-Provider]]
====  GitHub Enterprise Added as Auth Provider

GitHub Enterprise is now added as an auth provider. OAuth facilitates a token
exchange flow between {product-title} and GitHub or GitHub Enterprise. You can
use the GitHub integration to connect to either GitHub or GitHub Enterprise. For
GitHub Enterprise integrations, you must provide the `hostname` of your instance
and can optionally provide a `ca` certificate bundle to use in requests to the
server.

See xref:../install_config/configuring_authentication.adoc#GitHub[Configuring
Authentication and User Agent] for more information.

[[ocp-311-sspi-connection-support-on-windows]]
==== SSPI Connection Support on Microsoft Windows (Technology Preview)

SSPI Connection Support on Microsoft Windows is currently in
xref:ocp-311-technology-preview[Technology Preview] and not for production
workloads.

`oc` now supports the Security Support Provider Interface (SSPI) to allow for SSO
flows on Windows. If you use the request header identity provider with a
GSSAPI-enabled proxy to connect an Active Directory server to {product-title},
users can automatically authenticate to {product-title} by using the `oc`  command
line interface from a domain-joined Windows computer.

See
xref:../install_config/configuring_authentication.adoc#windows-sspi-using-request-header[Configuring
Authentication and User Agent] for more information.

[[ocp-311-notable-technical-changes]]
== Notable Technical Changes

{product-title} 3.11 introduces the following notable technical changes.

[discrete]
[[ocp-311-cluster-scoped]]
==== subjectaccessreviews.authorization.openshift.io and resourceaccessreviews.authorization.openshift.io Are Cluster-scoped Only

*_subjectaccessreviews.authorization.openshift.io_* and
*_resourceaccessreviews.authorization.openshift.io_* are now cluster-scoped
*only. If you need namespace-scoped requests, use
**_localsubjectaccessreviews.authorization.openshift.io_* and
*_localresourceaccessreviews.authorization.openshift.io_*.

[discrete]
[[ocp-311-scc-new-options]]
==== New SCC options

SCC has new options:


* `AllowPrivilegeEscalation`
* `DefaultAllowPrivilegeEscalation`
* `forbiddenSysctls`
* `allowedUnsafeSysctls`

[discrete]
[[ocp-311-oc-deploy-removed]]
==== Removed oc deploy Command

The `oc deploy` command, which was deprecated since {product-title} 3.7, is now
fully removed. Use `oc rollout` instead.

[discrete]
[[ocp-311-pipeline-plugin-now-deprecated]]
====  Pipeline Plug-in Is Deprecated

The {product-title} Pipeline Plug-in is deprecated but continues to work with
{product-title} versions up to version 3.11. For later versions of
{product-title}, either use the `oc` binary directly from your Jenkins
Pipelines, or use the {product-title} Client Plug-in.

[discrete]
[[ocp-311-logging-es5]]
====  Logging: Elasticsearch 5

Curator now works with Elasticsearch 5.

See
xref:../install_config/aggregate_logging.adoc#install-config-aggregate-logging[Aggregating
Container Logs] for additional information.

[discrete]
[[ocp-311-oc-env-and-oc-volume-removed]]
==== Removed oc env and oc volume Commands

The deprecated `oc env` and `oc volume` commands are now removed. Use `oc set
env` and `oc set volume` instead.

[discrete]
[[ocp-311-oc-ex-config-patch-command-removed]]
==== Removed the oc ex config patch Command

The `oc ex config patch` command will be removed in a future release, as it is
replaced by the `oc patch` command.

[discrete]
[[ocp-311-hawkular-now-deprecated]]
==== Hawkular Now Deprecated

Hawkular is now deprecated and will be removed in a future release.

[discrete]
[[ocp-311-oc-export-deprecated]]
==== oc export Now Deprecated

In {product-title} 3.10, `oc export` was deprecated. It will be removed in a
future release. Use `oc get --export` instead.

[discrete]
[[ocp-311-oc-types-now-deprecated]]
==== oc types Now Deprecated

In {product-title} 3.11, `oc types` is now deprecated. It will be removed in a
future release. Use official documentation instead.

[discrete]
[[ocp-311-ocp-uses-registry-redhat-io
==== {product-title} Now Uses registry.redhat.io

Instead of `registry.access.redhat.com`, {product-title} now uses
`registry.redhat.io` as the source of images for version 3.11. For access,
`registry.redhat.io` requires credentials.

[[ocp-311-bug-fixes]]
== Bug Fixes

This release fixes bugs for the following components:

*Builds*

* ConfigMap Build Sources allows you to use ConfigMaps as a build source, which
are transparent and easier to maintain than secrets. ConfigMaps can be injected
into any OpenShift build.
(link:https://bugzilla.redhat.com/show_bug.cgi?id=1540978[*BZ#1540978*])

* Information about out of memory (OOM) killed build pod gets propagated to a
build object. This simplifies debugging and helps you discover what went wrong
if appropriate failure reasons are described to the user. A build controller
populates correctly the status reason and message when build pod is OOM killed.
(link:https://bugzilla.redhat.com/show_bug.cgi?id=1596440[*BZ#1596440*])

* The logic for updating the build status waited to update the log snippet
containing the tail of the build log only ran after the build status was updated
to the failed state. The build would first transition to a failed state, then
get updated again with the log snippet.  This means code watching for the build
to enter a failed state would not see the log snippet value populated initially.
The code is now changed to populate the log snippet field when the build
transitions to failed, so the build update will contain both the failed state
and the log snippet. Code that watches the build for a transition to failed
state will see the log snippet as part of the update that transitioned the build
to failed, instead of seeing a secondary update later.
(link:https://bugzilla.redhat.com/show_bug.cgi?id=1596449[*BZ#1596449*])

*Cloud Compute*

* You can now configure NetworkManager for `dns=none` during installation. This is
commonly used when deploying on Microsoft Azure, but can also be useful in other
scenarios. In order to configure this, set
`openshift_node_dnsmasq_disable_network_manager_dns=true`.
(link:https://bugzilla.redhat.com/show_bug.cgi?id=1535340[*BZ#1535340*])

*Image*

List is WIP

[[ocp-311-technology-preview]]
== Technology Preview Features

Some features in this release are currently in Technology Preview. These
experimental features are not intended for production use. Please note the
following scope of support on the Red Hat Customer Portal for these features:

link:https://access.redhat.com/support/offerings/techpreview[Technology Preview
Features Support Scope]

In the table below, features marked *TP* indicate _Technology Preview_ and
features marked *GA* indicate _General Availability_.

.Technology Preview Tracker
[cols="4",options="header"]
|====
|Feature |OCP 3.9 |OCP 3.10 |OCP 3.11

|xref:ocp-311-prometheus[Prometheus Cluster Monitoring]
|TP
|TP
|GA

|xref:../install_config/persistent_storage/persistent_storage_local.adoc#install-config-persistent-storage-persistent-storage-local[Local Storage Persistent Volumes]
|TP
|TP
|TP

|CRI-O for runtime pods
|GA
|GA* footnoteref:[disclaimer, Features marked with `*` indicate delivery in a z-stream patch.]
|GA

|xref:ocp-311-tenant-driven-storage-snapshotting[Tenant Driven Snapshotting]
|TP
|TP
|TP

|xref:ocp-311-cli-plug-ins[`oc` CLI Plug-ins]
|TP
|TP
|TP

|Service Catalog
|GA
|GA
|GA

|xref:../architecture/service_catalog/template_service_broker.adoc#arch-template-service-broker[Template Service Broker]
|GA
|GA
|GA

|xref:../architecture/service_catalog/ansible_service_broker.adoc#arch-ansible-service-broker[OpenShift Automation Broker]
|GA
|GA
|GA

|xref:../admin_guide/managing_networking.adoc#admin-guide-networking-networkpolicy[Network Policy]
|GA
|GA
|GA

|Service Catalog Initial Experience
|GA
|GA
|GA

|New Add Project Flow
|GA
|GA
|GA

|Search Catalog
|GA
|GA
|GA

|CFME Installer
|GA
|GA
|GA

|xref:../dev_guide/cron_jobs.adoc#dev-guide-cron-jobs[Cron Jobs]
|GA
|GA
|GA

|xref:../dev_guide/deployments/kubernetes_deployments.adoc#dev-guide-kubernetes-deployments-support[Kubernetes Deployments]
|GA
|GA
|GA

|StatefulSets
|GA
|GA
|GA

|xref:../admin_guide/quota.adoc#limited-resources-quota[Explicit Quota]
|GA
|GA
|GA

|xref:../architecture/additional_concepts/storage.adoc#pv-mount-options[Mount Options]
|
|GA
|GA

|System Containers for docker, CRI-O
|Dropped
|-
|-

|xref:../install/running_install.adoc#running-the-advanced-installation-system-container[Installing from a System Container]
|GA
|GA
|GA

|Hawkular Agent
|-
|-
|-

|Pod PreSets
|-
|-
|-

|xref:../admin_guide/overcommit.adoc#configuring-reserve-resources[experimental-qos-reserved]
|TP
|TP
|TP

|xref:../admin_guide/sysctls.adoc#admin-guide-sysctls[Pod sysctls]
|TP
|TP
|TP

|xref:../install_config/master_node_configuration.adoc#master-node-config-audit-config[Central Audit]
|GA
|GA
|GA

|xref:../admin_guide/managing_networking.adoc#enabling-static-ips-for-external-project-traffic[Static IPs for External Project Traffic]
|GA
|GA
|GA

|xref:../dev_guide/templates.adoc#waiting-for-template-readiness[Template Completion Detection]
|GA
|GA
|GA

|xref:../cli_reference/basic_cli_operations.adoc#object-types[`replicaSet`]
|GA
|GA
|GA

|xref:../install_config/aggregate_logging.adoc#aggregated-fluentd[Mux]
|TP
|TP
|TP

|Clustered MongoDB Template
|-
|-
|-

|Clustered MySQL Template
|-
|-
|-

|xref:../dev_guide/managing_images.adoc#using-is-with-k8s[Image Streams with Kubernetes Resources]
|GA
|GA
|GA

|xref:../dev_guide/device_manager.adoc#using-device-manager[Device Manager]
|TP
|GA
|GA

|xref:ocp-311-pv-resize[Persistent Volume Resize]
|TP
|TP
|TP

|xref:../scaling_performance/managing_hugepages.adoc#scaling-performance-managing-huge-pages[Huge Pages]
|TP
|GA
|GA

|xref:../scaling_performance/using_cpu_manager.adoc#scaling-performance-using-cpu-manager[CPU Manager]
|TP
|GA
|GA

|xref:../dev_guide/device_plugins.adoc#using-device-plugins[Device Plug-ins]
|TP
|GA
|GA

|xref:ocp-311-syslog-output-plugin-for-fluentd[syslog Output Plug-in for fluentd]
|TP
|TP
|TP

|xref:ocp-311-container-storage-Interface[Container Storage Interface (CSI)]
|-
|TP
|TP

|xref:ocp-311-pv-provisioning-using-openstack-manilla[Persistent Volume (PV) Provisioning Using OpenStack Manila]
|-
|TP
|TP

|xref:ocp-311-node-problem-detector[Node Problem Detector]
|-
|TP
|TP

|xref:ocp-311-local-ephemeral-storage[Protection of Local Ephemeral Storage]
|-
|TP
|TP

|xref:ocp-311-the-descheduler[Descheduler]
|-
|TP
|TP

|xref:ocp-311-podman[Podman]
|-
|TP
|TP

|xref:ocp-311-kuryr[Kuryr CNI Plug-in]
|-
|TP
|TP

|xref:ocp-311-control-sharing-pid-namespace-between-containers[Sharing Control of the PID Namespace]
|-
|TP
|TP

|xref:ocp-311-cluster-admin-console[Cluster Administrator console]
|-
|-
|GA

|xref:ocp-311-cluster-autoscaling[Cluster Autoscaling (AWS Only)]
|-
|-
|GA

|Operator Lifecycle Manager
|-
|-
|TP

|====

[[ocp-311-known-issues]]
== Known Issues

* Due to a change in the authentication for the Kibana web console, you must log
back into the console after upgrade and every 168 hours after initial log in.
The Kibana console was migrated to *oauth-proxy*.
(link:https://bugzilla.redhat.com/show_bug.cgi?id=1614255[*BZ#1614255*])

[[ocp-311-asynchronous-errata-updates]]
== Asynchronous Errata Updates

Security, bug fix, and enhancement updates for {product-title} 3.11 are released
as asynchronous errata through the Red Hat Network. All {product-title} 3.11
errata is https://access.redhat.com/downloads/content/290/[available on the Red
Hat Customer Portal]. See the
https://access.redhat.com/support/policy/updates/openshift[{product-title}
Life Cycle] for more information about asynchronous errata.

Red Hat Customer Portal users can enable errata notifications in the account
settings for Red Hat Subscription Management (RHSM). When errata notifications
are enabled, users are notified via email whenever new errata relevant to their
registered systems are released.

[NOTE]
====
Red Hat Customer Portal user accounts must have systems registered and consuming
{product-title} entitlements for {product-title} errata notification
emails to generate.
====

This section will continue to be updated over time to provide notes on
enhancements and bug fixes for future asynchronous errata releases of
{product-title} 3.11. Versioned asynchronous releases, for example with the form
{product-title} 3.11.z, will be detailed in subsections. In addition, releases in
which the errata text cannot fit in the space provided by the advisory will be
detailed in subsections that follow.

[IMPORTANT]
====
For any {product-title} release, always review the instructions on
xref:../upgrading/index.adoc#install-config-upgrading-index[upgrading your cluster] properly.
====
