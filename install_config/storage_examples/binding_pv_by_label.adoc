[[binding-pv-by-label]]
= Binding Persistent Volumes by Labels
{product-author}
{product-version}
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:
:prewrap:

toc::[]

[[binding-pv-by-label-overview]]
== Overview
This topic provides an end-to-end example for binding
xref:../../architecture/additional_concepts/storage.adoc#persistent-volume-claims[persistent volume claims] (PVCs)
to
xref:../../architecture/additional_concepts/storage.adoc#persistent-volumes[persistent volumes] (PVs)
by defining labels in the PV and matching selectors in the PVC.  This feature is
available for all
xref:../persistent_storage/index.adoc#[storage options].  It is assumed that
a {product-title} cluster is running a storage volume is available for binding.

===== _A note on Labels and Selectors_
Labels are an {product-title} feature that allow for user defined tags to be
included with object specifications.  Their primary purpose is to enable the
arbitrary grouping of objects by defining identical labels among them.  These
labels can then be targeted by selectors to access all objects with matching
label values. It is this functionality we will take advantage of to enable our
PVC to bind to our PV.  For a more in-depth look at labels, refer to
xref:../../architecture/core_concepts/pods_and_services.adoc#labels[Pods and Services].

[NOTE]
====
For this example, we will be using modified
xref:../persistent_storage/persistent_storage_glusterfs.adoc#[GlusterFS]
PV and PVC specifications.  However, implementation of selectors and labels is
 the same for all storage options.  Refer to the
 xref:../persistent_storage/index.adoc#[relevant storage option] for your volume
provider to learn more about its unique configuration.
====

[[binding-pv-by-label-assumptions]]
=== Assumptions
* An existing {product-title} cluster with at least one *master* and one *node*
* At least one supported  xref:../persistent_storage/index.adoc#[storage volume]
* A user with *cluster-admin* privileges

[[binding-pv-by-label-define]]
== Defining Specifications

[NOTE]
====
These specifications are tailored to *GlusterFS*. Consult the
xref:../persistent_storage/index.adoc#[relevant storage option] for your volume
provider to learn more about its unique configuration.
====

==== Persistent Volume with Labels
.glusterfs-pv.yaml
====
[source,yaml]
----
apiVersion: v1
kind: PersistentVolume
metadata:
  name: gluster-volume
  labels: <1>
    storage-tier: gold
    aws-availability-zone: us-east-1
spec:
  capacity:
    storage: 2Gi
  accessModes:
    - ReadWriteMany
  glusterfs:
    endpoints: glusterfs-cluster
    path: myVol1
    readOnly: false
  persistentVolumeReclaimPolicy: Recycle
----
<1> Use labels to identify common attributes or characteristics shared among
 volumes. In this case, we assume that this glusterFS volume is a member of a
 fictional `gold-tier` level of storage.
====

==== Persistent Volume Claim with Selectors


It is important to note that a PVC will attempt to match *all* labels included
in the `selectors` stanza.  If no PV exists with an identical set of labels, the
PVC will remain unbound.

.glusterfs-pvc.yaml
====
[source,yaml]
----
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: gluster-claim
spec:
  accessModes:
  - ReadWriteMany
  resources:
     requests:
       storage: 1Gi
  selector: <1>
    matchLabels:
      storage-tier: gold
      aws-availability-zone: us-east-1
----
<1> The `selectors` stanza will container all labels to against which the PVC
must bind
====

==== Volume Endpoints

To attach the PV to the storage volume, endpoints should be configured before
creating our objects.

.glusterfs-ep.yaml
====
[source,yaml]
----
  apiVersion: v1
  kind: Endpoints
  metadata:
    name: glusterfs-cluster
  subsets:
    - addresses:
        - ip: 192.168.122.221
      ports:
        - port: 1
    - addresses:
        - ip: 192.168.122.222
      ports:
        - port: 1
----
====

=== Deploy the pv, pvc, and endpoints

For this example, we will be running `oc` commands as a *cluster-admin*
privileged user.  In a production environment, cluster clients might be expected
 to define and create the PVC.

----
# oc create  -f glusterfs-ep.yaml
endpoints "glusterfs-cluster" created
# oc create -f glusterfs-pv.yaml
persistentvolume "gluster-volume" created
# oc create -f glusterfs-pvc.yaml
persistentvolume "gluster-volume" created
----

Lastly, confirm that the PV and PVC bound successfully.

----
# oc get pv,pvc
NAME              CAPACITY   ACCESSMODES      STATUS     CLAIM                     REASON    AGE
gluster-volume    2Gi        RWX              Bound      gfs-trial/gluster-claim             7s
NAME              STATUS     VOLUME           CAPACITY   ACCESSMODES               AGE
gluster-claim     Bound      gluster-volume   2Gi        RWX                       7s
----
